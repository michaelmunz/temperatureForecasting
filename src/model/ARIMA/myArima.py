import numpy as np

#own classes
import src.config as cfg
import src.preprocess.Preprocess as pre
#ARIMA
import warnings
from statsmodels.tsa.statespace.sarimax import SARIMAX
from multiprocessing import cpu_count
from joblib import Parallel
from joblib import delayed

# grid search
from sklearn.metrics import mean_squared_error
from warnings import catch_warnings
from warnings import filterwarnings

# create a set of sarima configs to try
def sarima_configs(seasonal=[0]):
    models = list()
    # define config lists
    p_params = [0, 1]
    d_params = [1]
    q_params = [0, 1]
    t_params = ['n']
    # t_params = ['n','c','t','ct']
    P_params = [0 ,1]
    D_params = [1]
    Q_params = [0 ,1]
    m_params = seasonal
    # create config instances
    for p in p_params:
        for d in d_params:
            for q in q_params:
                for t in t_params:
                    for P in P_params:
                        for D in D_params:
                            for Q in Q_params:
                                for m in m_params:
                                    cfg = [(p,d,q), (P,D,Q,m), t]
                                    models.append(cfg)
    return models

# root mean squared error or rmse
def measure_rmse(actual, predicted):
    return np.sqrt(mean_squared_error(actual, predicted))

# split a univariate dataset into train/test sets
def train_test_split(data, n_test):
    return data[:-n_test], data[-n_test:]

# walk-forward validation for univariate data
def walk_forward_validation(data, n_test, cfg):
    # split dataset
    train, test = train_test_split(data, n_test)
    order, sorder, trend = cfg
    # estimate prediction error
    model = SARIMAX(train,
                 order=order,
                 seasonal_order=sorder,
                 trend=trend,
                 enforce_stationarity=False,
                 enforce_invertibility=False)
    model_fit = model.fit(disp=False)
    forecast = model_fit.forecast(n_test)

    error = measure_rmse(test, forecast)
    return error

# score a model, return None on failure
def score_model(data, n_test, cfg, debug=False):
    result = None
    # convert config to a key
    key = str(cfg)
    # show all warnings and fail on exception if debugging
    if debug:
        result = walk_forward_validation(data, n_test, cfg)
    else:
        # one failure during model validation suggests an unstable config
        try:
            # never show warnings when grid searching, too noisy
            with catch_warnings():
                filterwarnings("ignore")
                result = walk_forward_validation(data, n_test, cfg)
        except:
            error = None
    # check for an interesting result
    #if result is not None:
    #    print(' > Model[%s] %.3f' % (key, result))
    return (key, result)

# grid search configs
def grid_search(data, cfg_list, n_test, parallel=False):
    scores = None
    if parallel:
        # execute configs in parallel
        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')
        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)
        scores = executor(tasks)
    else:
        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]
    # remove empty results
    scores = [r for r in scores if r[1] != None]
    # sort configs by error, asc
    #scores.sort(key=lambda tup: tup[1])
    return scores

class myArima:
    def __init__(self):
        #print("Initializing ARIMA")

        prep = pre.DataPreprocessing()
        self.dataX, self.datay = prep.load_selected()


    def SARIMA(self,idx, numpredictions, order=(0,1,1), seasonal_order=(0,1,1,24), trend=None):

        # use every hour to gain the parameters
        nDays = 7*4
        trainingData = self.dataX[max(idx-nDays*24,0):idx,cfg.prediction['pos']]
        model = SARIMAX(trainingData, order=order,
                          trend=trend,
                          seasonal_order=seasonal_order,
                          enforce_stationarity=False,
                          enforce_invertibility=False)
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore")
            self.trained_model = model.fit(disp=False)
        pred = self.trained_model.forecast(cfg.prediction['num_predictions'])
        return pred

    def SARIMA_GridSearch(self,idx, numpredictions):
        nDays = 7
        trainingData = self.dataX[(idx-(nDays*24)-1):(idx),cfg.prediction['pos']]
        cfg_list = sarima_configs(seasonal=[24])

        # do the grid search on the training data
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore")
            #scores = grid_search(trainingData, cfg_list, cfg.prediction['num_predictions'], parallel=False)
            scores = grid_search(trainingData, cfg_list, 1, parallel=True)

        err = list()
        for i,data in enumerate(scores):
            err.append(data[1])
        index = err.index(min(err))
        # train the modell with the last 7 days and predict
        trainingData = self.dataX[max(idx-nDays*24,0):(idx),cfg.prediction['pos']]

        order = cfg_list[index][0]
        season_order = cfg_list[index][1]
        trend = cfg_list[index][2]

        #print('order = ', order)
        #print('season_order = ', season_order)
        #print('season_order = ', trend)

        model = SARIMAX(trainingData,
                        order=order,
                        seasonal_order=season_order,
                        trend=trend,
                        enforce_invertibility=False,
                        enforce_stationarity=False)
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore")
            self.trained_model = model.fit(disp=False)
        pred = self.trained_model.forecast(cfg.prediction['num_predictions'])
        return pred
