# -*- coding: utf-8 -*-
#This class should preprocess the IMU data
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder

from sklearn.model_selection import train_test_split
import sys
import src.config as cfg
import pickle

class DataPreprocessing:

    def __init__(self,onehotbool = False,labeltype = ""):        
        self.samples = list()
        self.samplelabels = list()
        self.testsamples = list()
        self.testsamplelables = list()
        self.treadmillsamples = list()  
        self.fulldatalist = list()       
        self.datalist = list()
        self.testbool = False
        self.onehotbool = onehotbool #onehot encoding?!
        
    def onehotencoding(self, dataY):      
        onehot_encoder = OneHotEncoder(sparse=False,categories='auto')
        dataY = dataY.reshape(len(dataY), 1)
        dataY = onehot_encoder.fit_transform(dataY)
        return dataY
        
    def loaddata(self, datapath):
        df = pd.read_csv(datapath,sep=';')
        timesteps = np.arange(np.array(df["date"]).shape[0])
        #df = df.drop(['ID'],axis=1)        
        
        datalist = list()
        fulldatalist = list()
        for listitem in cfg.fields['allfields']:
            data = df[listitem].values
            datalist.append(data)
        
        
        tempdata = np.transpose(np.array(datalist))    
        fulldatalist.append(tempdata)
        fulldata = np.array(fulldatalist)        
        fulldata = np.reshape(fulldata,(fulldata.shape[0]*fulldata.shape[1],fulldata.shape[2]))
        return fulldata, timesteps
    
    def scaleX(self,dataX):
        scaler_X = MinMaxScaler(feature_range=(0,1)).fit(dataX)
        dataX_scaled = scaler_X.transform(dataX)
        return dataX_scaled, scaler_X
        
    
    def load_selected(self, wind = False, scale = False):
        '''
        This function should load all the data specified in the config 
        '''
        Xlist = list()
        for data in cfg.data['datalist']:    
            X,t = self.loaddata(cfg.datapaths[data])
            Xlist.append(X)             
        
        dataX = np.concatenate( Xlist, axis=0 )
        
        if wind:
            Wind_direction = dataX[:,5]
            Wind_direction = self.onehotencoding(Wind_direction)
            dataX = np.delete(dataX, [5], axis = 1)
        
            ###### Scale ##################
            if scale:
                dataX_scaled, scaler_X = self.scaleX(dataX)
                file_scaler = open('saver/outputs/scaler/scaler.pckl', 'wb') 
                pickle.dump(scaler_X, file_scaler)
            
            dataX_scaled = np.concatenate((dataX_scaled,Wind_direction), axis = 1)
        else:
            ###### Scale ##################
            if scale:
                dataX_scaled, scaler_X = self.scaleX(dataX)
                file_scaler = open('saver/outputs/scaler/scaler.pckl', 'wb') 
                pickle.dump(scaler_X, file_scaler)
                
       
        
        datay = dataX[:,cfg.prediction['pos']]
        datay = np.reshape(datay,(datay.shape[0],1))
        
        if scale:
            dataX = dataX_scaled
        
        return dataX , datay


    def cutinSamples(self,fulldata,fulldataY, sample_length, timestepstopredict):       
        cfg.data['num_of_samples'] = int(fulldata.shape[0] / sample_length)
        num_of_samples = cfg.data['num_of_samples']
        samples = list()
        samplelabels = list()
        sampleinfo = list()
        
        for j in np.arange(num_of_samples-2):  
            windows = list()
            windowlabels = list()
            windowposition = list()
            
            for i in range(j*sample_length+ cfg.windowing['windowlength'],(j+1)*sample_length):# - cfg.windowing['windowlength'],cfg.windowing['windowshift']): 
                label = fulldataY[i:i + timestepstopredict,0] #schaue 1 windowlength in die Zukunft
                windowlabels.append(label)
                window = fulldata[i-cfg.windowing['windowlength']:i,:] 
                windows.append(window)
                windowposition.append(i)
          
            samples.append(windows)              
            samplelabels.append(windowlabels)
            sampleinfo.append(windowposition)
        return samples, samplelabels, sampleinfo
            
    ## FUNCTIONS
    def batch_generator(batch_size, sequence_length, num_x_signals, num_y_signals, num_train, 
                    x_train_scaled, y_train_scaled, h_prediction, test_bool = False):
        """
        Generator function for creating random batches of training-data.
        """
        # Infinite loop.
        while True:
            # Allocate a new array for the batch of input-signals.
             x_shape = (batch_size, sequence_length, num_x_signals)
             x_batch = np.zeros(shape=x_shape, dtype=np.float16)
         
             y_shape = (batch_size, h_prediction)
             y_batch = np.zeros(shape=y_shape, dtype=np.float16)
         
            # Fill the batch with random sequences of data.
             for i in range(batch_size):
                # Get a random start-index.
                # This points somewhere into the training-data.
                idx = np.random.randint(num_train - sequence_length-h_prediction)
                 
                # Copy the sequences of data starting at this index.
                x_batch[i] = x_train_scaled[idx:idx+sequence_length]
                ## if we test, we have only one batch, but we want to predict
                ## the next few hours
                y_batch[i] = y_train_scaled[idx+sequence_length:idx+sequence_length+h_prediction][:,0]
         
        yield (x_batch, y_batch)
        
    def update_progress(self,progress, train_test):
        # function from: https://stackoverflow.com/questions/3160699/python-progress-bar
        # and just a little bit modified by myself
        barLength = 20 # Modify this to change the length of the progress bar
        status = ""
        if isinstance(progress, int):
            progress = float(progress)
        if not isinstance(progress, float):
            progress = 0
            status = "error: progress var must be float\r\n"
        if progress < 0:
            progress = 0
            status = "Halt...\r\n"
        if progress >= 1:
            progress = 1
            status = "Done...\r\n"
        block = int(round(barLength*progress))
        text = "\r" + train_test + " Progress: [{0}] {1:.2f}% {2}".format( "#"*block + "-"*(barLength-block), progress*100, status)
        sys.stdout.write(text)
        sys.stdout.flush()
            
    def getsamples(self):
        return self.samples
    
    def getsamplelabels(self):
        return self.samplelabels    
        
#   
#    def scaleX(self):
#        scaler = MinMaxScaler().fit(self.fulldata)
#        self.fulldata = scaler.transform(self.fulldata)
#        return scaler
        
    
    def getsplitsamples(self, test_size = 0.33, shuffle = False):
        a= self.samples
        b=self.samplelabels
        samples_train, samples_test, samplelabels_train, samplelabels_test = train_test_split(self.samples, self.samplelabels, test_size=test_size, random_state=60,shuffle=shuffle)
        
        samples_train = np.array(samples_train)
        samplelabels_train = np.array(samplelabels_train)
        samples_test = np.array(samples_test)
        samplelabels_test = np.array(samplelabels_test)
        
        samples_train = np.reshape(samples_train,(samples_train.shape[0]*samples_train.shape[1],samples_train.shape[2],samples_train.shape[3]))
        samplelabels_train = np.reshape(samplelabels_train,(samplelabels_train.shape[0]*samplelabels_train.shape[1],samplelabels_train.shape[2]))
        
        samples_test = np.reshape(samples_test,(samples_test.shape[0]*samples_test.shape[1],samples_test.shape[2],samples_test.shape[3]))
        samplelabels_test = np.reshape(samplelabels_test,(samplelabels_test.shape[0]*samplelabels_test.shape[1],samplelabels_test.shape[2]))
        
        return samples_train, samplelabels_train, samples_test, samplelabels_test
        
        