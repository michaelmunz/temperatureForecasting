from textwrap import wrap
import glob, re
import pickle
#import math
#import itertools
#import tfplot # import tensorflow-plot
import matplotlib.pyplot as plt
import matplotlib as mplt
import seaborn as sns
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import src.model.ARIMA.myArima as myAR_file
import src.preprocess.Preprocess as pre

import src.config as cfg
import src.model.myConvLSTMLayers as layers
import tensorflow as tf
import cv2
from sklearn.metrics import mean_squared_error
import datetime
from math import sqrt


class myVisualization:
    '''
    This class should take care of visualisation tasks in any form
    '''
    
    def __init__(self, datapath):
        self.datapath = datapath
        print("Visualisierung wird vorbereitet")
        
    #%% Error Visualisation
    def natural_sort(self,l): 
        convert = lambda text: int(text) if text.isdigit() else text.lower() 
        alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] 
        return sorted(l, key = alphanum_key)
        
    def load_saved_files(self, selected_data, file= -1): 
        prep = pre.DataPreprocessing()

        if selected_data == 'val':
            val_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Validation/*.pckl')):
                with open(path,'rb') as f:
                    val_list.append(pickle.load(f))
            self.x = val_list[file][0]
            self.true = val_list[file][1]  
            self.pred = val_list[file][2]
            info_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Validation/extraData/*.pckl')):
                with open(path,'rb') as f:
                    info_list.append(pickle.load(f))
            self.info1 = np.reshape(info_list[file],(info_list[file].shape[0]))  
            conv6_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Validation/Activations/c*.pckl')):
                with open(path,'rb') as f:
                    conv6_list.append(pickle.load(f))
            self.conv6_list = conv6_list
        
        if selected_data == 'train':
            train_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Train/*.pckl')):
                with open(path,'rb') as f:
                    train_list.append(pickle.load(f))
            self.x = train_list[file][0]
            self.true= train_list[file][1]  
            self.pred= train_list[file][2]        
            info_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Train/extraData/*.pckl')):
                with open(path,'rb') as f:
                    info_list.append(pickle.load(f))
            self.info1 = np.reshape(info_list[file],(info_list[file].shape[0])) 
            conv6_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Train/Activations/c*.pckl')):
                with open(path,'rb') as f:
                    conv6_list.append(pickle.load(f))
            self.conv6_list = conv6_list
            
            
            
        if selected_data == 'test':
            test_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Test/*.pckl')):
                with open(path,'rb') as f:
                    test_list.append(pickle.load(f))
            self.x = test_list[file][0]
            self.true = test_list[file][2]  
            self.pred = test_list[file][1] 
            
           
            
            info_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Test/extraData/*.pckl')):
                with open(path,'rb') as f:
                    info_list.append(pickle.load(f))
            self.info1 = np.reshape(info_list[file],(info_list[file].shape[0]))  
            
            conv6_list= list()
            for path in self.natural_sort(glob.glob(self.datapath + '/Prediction_Test/Activations/c*.pckl')):
                with open(path,'rb') as f:
                    conv6_list.append(pickle.load(f))
            self.conv6_list = conv6_list
            
        infile = open(self.datapath + '/Prediction_Test_onlyLSTM/LSTM_ALLchannels_model.pckl','rb')
        self.LSTMmodel = pickle.load(infile, encoding='bytes')
        infile2 = open(self.datapath + '/Prediction_Test_onlytemp/LSTM_onlyTemp_model.pckl','rb')
        self.LSTMmodel_onechannel = pickle.load(infile2, encoding='bytes')
        self.scaleddataX , dataY = prep.load_selected(wind=True,scale=True)
        self.dataX, self.datay = prep.load_selected()

    def mean_absolute_percentage_error(self, y_true, y_pred): 
        y_true, y_pred = np.array(y_true), np.array(y_pred)
        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100    
        
    def mean_absolute_scaled_error(self, y_true, y_pred, y_naiv): 
        y_true, y_pred, y_naiv = np.array(y_true), np.array(y_pred), np.array(y_naiv)
        mae_naiv = np.mean(np.abs(y_true-y_naiv))
        return np.mean(np.abs((y_true - y_pred) / mae_naiv))
    
    def visualizeTS(self, selected_dat="val", count = 10, arima = True, visualTS = False):
        #%% Visualize timeseries
        x_arima_list = list()
        self.load_saved_files(selected_dat)
        self.arima=arima 
        x_before_list = list()
        x_after_list = list()
        
        errNN = list()
        errNNLSTM = list()
        errNNLSTM2 = list()
        errArima = list()
        errNaiv = list()
        
        rmseNaiv = list()
        rmseArima = list()
        rmseNN = list()
        rmseNNLSTM = list()
        rmseNNLSTM2 = list()
        
        
        maseNaiv = list()
        maseArima = list()
        maseNN = list()
        maseNNLSTM = list()
        maseNNLSTM2 = list()
        
        if count == -1:
            count = self.pred.shape[0]-100
        for i in 100 + 1*np.arange(count):  
            print(i)
            
            #vis.compare_data(i,selected_data="val")
            pred_naiv, pred_arima, x_before, x_after, y_true, pred_nn, pred_nnLSTM, pred_nnLSTM2 = self.compare_data(i,selected_data=selected_dat,
                                               order=(0,1,1), seasonal_order=(0,1,1,24), flag=visualTS)
        
            errNaiv.append(y_true-pred_naiv)
            errNN.append(y_true-pred_nn)
            errNNLSTM.append(y_true-pred_nnLSTM)
            errNNLSTM2.append(y_true-pred_nnLSTM2)
        
            x_before_list.append(x_before)          
            x_after_list.append(x_after)
            
            rmseNaiv.append(sqrt(mean_squared_error(y_true, pred_naiv)))
            rmseNN.append(sqrt(mean_squared_error(y_true, pred_nn)))
            rmseNNLSTM.append(sqrt(mean_squared_error(y_true, pred_nnLSTM)))
            rmseNNLSTM2.append(sqrt(mean_squared_error(y_true, pred_nnLSTM2)))
            
            maseNaiv.append(self.mean_absolute_scaled_error(y_true, pred_naiv, pred_naiv))
            maseNN.append(self.mean_absolute_scaled_error(y_true, pred_nn, pred_naiv))
            maseNNLSTM.append(self.mean_absolute_scaled_error(y_true, pred_nnLSTM, pred_naiv))
            maseNNLSTM2.append(self.mean_absolute_scaled_error(y_true, pred_nnLSTM2, pred_naiv))
            
            if arima:
                errArima.append(y_true-pred_arima)
                x_arima_list.append(x_before)
                maseArima.append(self.mean_absolute_scaled_error(y_true, pred_arima, pred_naiv))
                rmseArima.append(sqrt(mean_squared_error(y_true, pred_arima)))
                
            if arima == False:
                errArima = -9999
        return errNaiv, errArima, errNN, errNNLSTM, errNNLSTM2, x_after_list
        
    def compare_data(self,sample,selected_data='val', flag=0, order=(0,1,1), seasonal_order=(0,1,1,24), trend=None, grid_search=0):
        x_before = np.arange(cfg.windowing['windowlength'])
        y_before = self.dataX[self.info1[sample]-cfg.windowing['windowlength']:self.info1[sample],cfg.prediction['pos']]
#        true = self.dataX[self.info1[sample]:self.info1[sample]+cfg.windowing['windowlength'],cfg.prediction['pos']]

        x_after =  cfg.windowing['windowlength']  + np.arange(cfg.prediction['num_predictions'])
        sampleX = self.scaleddataX[self.info1[sample]-cfg.windowing['windowlength']:self.info1[sample],:]
        sampleX = sampleX.reshape((1,sampleX.shape[0], sampleX.shape[1]))        
        onlyLSTM_pred = self.LSTMmodel.predict(sampleX)
        onlyLSTM_pred = onlyLSTM_pred.reshape((onlyLSTM_pred.shape[1]))
        sampleX2 = sampleX[:,:,cfg.prediction['pos']]
        sampleX2 = sampleX2.reshape((1,sampleX.shape[1], 1))
        onlyLSTM2_pred = self.LSTMmodel_onechannel.predict(sampleX2)
        onlyLSTM2_pred = onlyLSTM2_pred.reshape((onlyLSTM2_pred.shape[1]))
        # SARIMA
        #y_before_arima = y_before_all[:,cfg.prediction['pos']]
        
        if self.arima:
            myAR = myAR_file.myArima()    #
            if grid_search == False:
                arima_pred = myAR.SARIMA(self.info1[sample],cfg.prediction['num_predictions'], order=order, seasonal_order=seasonal_order, trend=trend)
            elif grid_search == True:
                arima_pred = myAR.SARIMA_GridSearch(self.info1[sample],cfg.prediction['num_predictions'])


        timeSeries = self.dataX[max(self.info1[sample]-24,0):self.info1[sample],cfg.prediction['pos']]
        naiv_pred = list()
        for i in range(0,cfg.prediction['num_predictions']):
            naiv_pred.append(timeSeries[(len(timeSeries)+i-24)])
            
        if flag == 1: 
            df = pd.read_csv(cfg.datapaths['data'],sep=';')
            date = np.array(df['date'][(self.info1[sample]-cfg.windowing['windowlength']):(self.info1[sample]+cfg.prediction['num_predictions'])])
            date_time_low = datetime.datetime.strptime(str(date[0]), '%Y%m%d%H')            
            date_time_high = datetime.datetime.strptime(str(date[-1]), '%Y%m%d%H')            
            idx = pd.date_range(date_time_low, date_time_high, freq = 'H')
            


            plt.figure()


            # blue
            a1, a2, a3 = 0/256, 85/256 , 163/256
            # red 
            b1, b2, b3 = 139/256, 0/256 , 0/256
            # green
            c1, c2, c3 = 34/256, 139/256 , 34/256

#            plt.plot(idx, np.concatenate([y_before, true]),'k', label = r'True')
            plt.plot(idx, np.concatenate([y_before, self.true[sample,:]]),'k', label = r'True')
            plt.plot(idx[-cfg.prediction['num_predictions']:],self.pred[sample,:],'-o', label = r'convLSTM', markersize=4, color=(a1,a2,a3))
            plt.plot(idx[-cfg.prediction['num_predictions']:], onlyLSTM_pred,'-*', label = r'LSTM', markersize=4, color='m')
            if self.arima:
                plt.plot(idx[-cfg.prediction['num_predictions']:], arima_pred,'-x', label = r'SARIMA', markersize=4, color=(b1,b2,b3))
            plt.plot(idx[-cfg.prediction['num_predictions']:], naiv_pred,'-^', label = r'Seasonal Naiv', markersize=4, color=(c1,c2,c3))

            from matplotlib.dates import DateFormatter
            #formatter = DateFormatter('%Y-%m-%d %H:%M')
            formatter = DateFormatter('%H:%M')
            plt.gcf().axes[0].xaxis.set_major_formatter(formatter)
            plt.gcf().autofmt_xdate()

            #plt.xlabel(r'Zeit (h)')
            plt.ylabel(r'Temperatur ($^\circ$C)')
            #plt.xlabel(r'time (h)')
            plt.xlabel(r'')
            #plt.ylabel(r'temperature ($^\circ$C)')
            plt.grid()
            plt.legend(loc='lower left')
            plt.show()

            #path = "solution/time_series_" + str(self.info1[sample]) + ".pdf"
           #plt.savefig(path , bbox_inches='tight')
                
        #print('MSE_NN: ', mean_squared_error(self.true[sample,:], self.pred[sample,:]))
        #print('MSE_ARIMA: ', mean_squared_error(yTrue, pred_arima))
        #print()
        if self.arima == False:
               arima_pred = -9999
#        return naiv_pred, arima_pred, x_before, x_after,true , self.pred[sample,:], onlyLSTM_pred     
        return naiv_pred, arima_pred, x_before, x_after,self.true[sample,:], self.pred[sample,:], onlyLSTM_pred, onlyLSTM2_pred
        
    def visualize_losses(self, start, end=-1, minimum = True):
        with open(self.datapath + '/losses/losses.pckl','rb') as f:
            losses = pickle.load(f)
    
        font = {'family': 'serif',
        'color':  'b',
        'weight': 'bold',
        'size': 12,
        }
        loss_train = losses[0]
        loss_val   = losses[1]
        minloss_val = np.min(loss_val)
        minloss_val_idx = np.argmin(loss_val)
        print(np.min(loss_train))
        print(loss_val[minloss_val_idx])
        
        plt.figure()        
        x = np.arange(loss_train.shape[0])
        plt.plot(x[start:end],loss_train[start:end],'-g', label = 'Training')
        plt.plot(x[start:end],loss_val[start:end],'-r', label = 'Validation')
        if minimum:
            plt.plot(minloss_val_idx,loss_val[minloss_val_idx],'bx',markersize = 10)
            plt.text(start, np.max(loss_val[start:end])-8, 'Minumum =' + str(float("{0:.4f}".format(minloss_val)))+ ' Epoche: ' + str(float("{0:.4f}".format(minloss_val_idx))), fontdict=font)
        plt.title('Losses')
        plt.xlabel('epoch')
        plt.ylabel('MSE')
        
        plt.legend()
        plt.show()    
        
    def visualize_timeSeries(self,sample, selected_data ='val'):
        x_before = np.arange(cfg.windowing['windowlength'])
        x_after =  cfg.windowing['windowlength']  + np.arange(cfg.prediction['num_predictions'])
        self.load_saved_files(selected_data)
        file_scaler = open('saver/outputs/scaler/scaler.pckl', 'rb') 
        scaler = pickle.load(file_scaler)
        y_before_all = scaler.inverse_transform(self.x[sample,:,:,0])
        y_before = y_before_all[:,cfg.prediction['pos']]
        
        plt.figure() 

        plt.plot(x_before,y_before,'b', label = 'measurements')
        plt.plot(x_after,self.pred[sample,:],'r', label = 'Prediction')
        plt.plot(x_after,self.true[sample,:],'g', label = 'True')
        plt.legend()
        
   
    def visualze_meanerror(self, selected_data ='val'):  
        font = {'family': 'serif',
        'color':  'darkred',
        'weight': 'bold',
        'size': 16,
        }   
        
        self.load_saved_files(selected_data)
        
        error = self.true-self.pred
        mean_error = np.mean(error, axis=1)
        mu = np.mean(mean_error)
        sigma  = np.std(mean_error)
        plt.figure()
        plt.scatter(np.arange(mean_error.shape[0]),mean_error)
        plt.text(0, np.max(mean_error)-1, str(float("{0:.2f}".format(mu))) + ' +- ' + str(float("{0:.2f}".format(sigma))), fontdict=font)
        plt.plot([0,len(error)],[mu,mu], 'r',linewidth = 3, label = 'mean')
        plt.plot([0,len(error)],[mu+sigma,mu+sigma], 'darkgreen', label='standard deviation')
        plt.plot([0,len(error)],[mu-sigma,mu-sigma], 'darkgreen')
        plt.legend(loc = 1)
        plt.title("mean absolute error of all predictions (samplewise)")
        plt.xlabel("sample number (1 dp = 1 step)")
        plt.ylabel("mean absoute error")        

    def visualze_tserror(self,timestep, selected_data ='val'):  
        font = {'family': 'serif',
        'color':  'darkred',
        'weight': 'bold',
        'size': 16,
        }   
        
        self.load_saved_files(selected_data)
        
        error = self.true-self.pred
        mean_error = error[:,timestep]
        mu = np.mean(mean_error)
        sigma  = np.std(mean_error)
        plt.figure()
        #plt.scatter(np.arange(mean_error.shape[0]),mean_error)
        plt.text(0, np.max(mean_error)-1, str(float("{0:.2f}".format(mu))) + ' +- ' + str(float("{0:.2f}".format(sigma))), fontdict=font)
        plt.plot([0,len(error)],[mu,mu], 'r',linewidth = 3, label = 'mean')
        plt.plot([0,len(error)],[mu+sigma,mu+sigma], 'darkgreen', label='standard deviation')
        plt.plot([0,len(error)],[mu-sigma,mu-sigma], 'darkgreen')
        plt.legend(loc = 1)
        plt.title("mean absolute error of all predictions (samplewise)")
        plt.xlabel("sample number (1 dp = 1 step)")
        plt.ylabel("absoute error in timestep" + str(timestep))    
        
        
    def visualze_meanerrorperstep(self,selected_data ='val'): 
        self.load_saved_files(selected_data)
        meanerrors = list()
        standarddeviations = list()
        steps_forward = np.arange(self.true.shape[1])
        
        for timestep in steps_forward:            
            error = self.true-self.pred
            mean_error = error[:,timestep]
            mu = np.mean(mean_error)
            meanerrors.append(mu)
            sigma  = np.std(mean_error)
            standarddeviations.append(sigma)

        plt.figure()
        plt.subplot(2,1,1)
        #plt.text(0, np.max(mean_error)-1, str(float("{0:.2f}".format(mu))) + ' +- ' + str(float("{0:.2f}".format(sigma))), fontdict=font)
        plt.plot(steps_forward,np.array(meanerrors), 'b',linewidth = 2, label = 'mean')
        plt.legend(loc = 1)
        plt.subplot(2,1,2)
        plt.plot(steps_forward,np.array(standarddeviations), 'b',linewidth = 2, label = 'standard deviation')
        plt.legend(loc = 1)
        plt.title("mean absolute error of all predictions ")
        plt.xlabel("timestep in the future (forecast) ")
        plt.ylabel("mean absoute error in timestep")    

        
    def get_cam(self,layer_output):  
        
        cam = np.zeros(dtype = np.float, shape = layer_output.shape[0:2])
        
        for i in range(layer_output.shape[2]):
            for w in range(layer_output.shape[1]):
                cam[:,w]  += layer_output[:,w,i]
        
    
        cam /= np.sum(cam)
        cam = np.abs(cam)
        cam = cv2.resize(cam,(710,1200))
        return cam
    
    def visualizecam(self,cam, IMUnumber = 10,channelnumber = 7): #treadmill_test, step,   
        
        font = {'family': 'serif',
        'color':  'darkred',
        'weight': 'bold',
        'size': 16,
        }
        
        cam =np.uint8((cam +1)*255/2)
        im_cloud_blur = cv2.GaussianBlur(cam,(5,5),0)
        
        
        plt.imshow(im_cloud_blur, origin="lower", cmap='jet', interpolation='nearest')
        plt.colorbar()
    
        plt.title('CAM')
        plt.xlabel('Location')
        plt.ylabel('Time')
        plt.show()
        
    def cam(self,sample=0, epoch=-1, selected_data='val'):        
        self.load_saved_files(selected_data)
        plt.figure()
        ### GET HEATMAP ###
        cam = self.get_cam(self.conv6_list[epoch][sample,:,:,:])
        ### VISUALIZE HEATMAP ###
        self.visualizecam(cam)#, treadmill_val_list[epoch], step)
        
