import shutil
shutil.rmtree('saver/outputs', ignore_errors=True)
shutil.copytree('saver/outputs.orig','saver/outputs')

# to make this notebook's output stable across runs
def reset_graph(seed=42):
    tf.reset_default_graph()
    np.random.seed(seed)
    
#############################    
##########IMPORT#############
#############################  

import src.config as cfg
import pandas as pd
import pickle
import numpy as np
import matplotlib.pyplot as plt
##Preprocess
import src.preprocess.Preprocess as pre
import src.model.convLSTM.myConvLSTM_backup as convLSTM
#Visualization
#import src.vis.myVisualization as Visualization
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder

#tensorflow
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()


cfg.NN_Dense['n_outputs'] = cfg.prediction['num_predictions'] ### forecasting

#%%##########################  
##### PREPROCESSING #########
############################# 
prep = pre.DataPreprocessing()
dataX, datay = prep.load_selected(wind=True, scale = True)

cfg.NN_input['width'] = dataX.shape[1]




samples, samplelabels, sampleinfo = prep.cutinSamples(dataX,datay,cfg.data['sequencelength'], cfg.prediction['num_predictions'])


## Split the data in training and testing (DO NOT SHUFFLE THE DATA)
X_train, X_test, y_train, y_test, info_train, info_test = train_test_split(samples, samplelabels, sampleinfo,
                                                    test_size = 0.3, 
                                                    random_state = 21, 
                                                    shuffle = True)

X_train, X_val, y_train, y_val, info_train, info_val = train_test_split(X_train, y_train, info_train,
                                                    test_size = 0.1, 
                                                    random_state = 42, 
                                                    shuffle = True)

#%%##########################  
##### Neural Network ########
############################# 
#cfg.Modelparameter_highlevel['batchsize'] =  int((cfg.data['sequencelength']-cfg.windowing['windowlength']))
cfg.Modelparameter_highlevel['n_epochs'] =1000
#cfg.Modelparameter_highlevel['dropout'] = 0.5 #0.2,
#cfg.Modelparameter_highlevel['learningrate'] = 0.00007

tf.reset_default_graph() #reset_graph()
#reset.ops_default_graph() #reset_graph()
myModel = convLSTM.myConvLSTM(X_train, X_val,X_test, y_train, y_val, y_test, info_train, info_val, info_test)
myModel.built_graph()
pred_test, y_test = myModel.runGraph()
